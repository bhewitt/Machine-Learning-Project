---
title: "Machine Learning Writeup"
author: "Brad Hewitt"
date: "Wednesday, September 17, 2014"
output: html_document
---
## Summary
Describe an overview of what you did in a few sentences.


### Study design
First, download the training and test sets from the source. The official training set will not be used until the very end.

```{r, download}
set.seed(12322)
# These only need to be run on the first time
# download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv","trainingdata.csv",method="auto")
# download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv","testingdata.csv",method="auto")

trainingdata <- read.csv("trainingdata.csv")
finaltesting <- read.csv("testingdata.csv")
```

Looking at the training data, there are 19,622 observations of 160 variables. This sample set is fairly large, so for the study desing we will spit the training set into training and test groups. We will use the training set to pick features and build the model. We will use k-fold cross validation on the training set to estimate the out of sample error and then apply to the test set to get a better estimate of the out of sample error. The code below separates 80% of the data into the training group, which will be divided up during cross-validation, and 20% into the testing group.

```{r, split}
library(caret);library(ggplot2)
inTrain <- createDataPartition(y=trainingdata$classe, p=.8, list=F)
training <- trainingdata[inTrain,]
testing <- trainingdata[-inTrain,]
```

### Covariate Selection
Building a model with 160 variables would be too resource intensive so we can reduce some of the variables before training the model.  

When reviewing the data, the variables are not all of the same type. There are two columns that are the index number and the user name. Plotting the index and classe shows that the different activity classes were recorded in order. 

```{r}
qplot(X,classe, colour = user_name,data=training)
```

There are 3 timestamp variables that appear to be recording when the activites were completed. We will ignore these in the final model.  
  
There also appear to be columns that are summaries or descriptions of the preceding columns. They have names such as "total_accel_belt" which can be interpreted as the total accelaration from the belt sensor. These columns will not be included in the final model.
```{r,cleanup}
names(training)
sumcols <- grep("X|user_name|timestamp|window|total|kurtosis|skewness|max|min|avg|var|stddev|amplitude",names(training))
trainingclean <- training[,-sumcols]
```
  
I will use prinicple component analysis to further reduce the covariates. After preprocessing with PCA, we can see that there are 23 variables that explain 95% of the variance after the variables are scaled and centered (the preProcess function defaults the threshold to .95).
```{r eval=FALSE}
preProc <- preProcess(trainingclean[,-49], method="pca")
preProc$rotation
```
  
### Fitting the model
The model fit will use the random forest method, after preprocessing with Principle Component Analysis.
```{r}
modFit <- train(classe ~ ., data = trainingclean, method = "rf", preProcess = "pca")
modFit2
```

Looking at the model output it estimates the out of sample accuracy as 96.7%. However, this is most likely an optimistic estimate as it was based on the training data. Applying to the model to the test data we set aside earlier will give a better estimate of the out of sample accuracy.
```{r}
confusionMatrix(predict(modFit2,testing),testing$classe)
```

In this case, the accuracy on the test data is slightly above what it was on the training data.

### Write the files for submission
```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
```

The code below writes the answers as individual files to be submitted.
```{r eval=FALSE}
answers <-as.character(predict(modFit, finaltesting))
pml_write_files(answers)
```
